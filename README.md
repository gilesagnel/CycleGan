# CycleGAN
This is an implementation of the CycleGAN model introduced in the paper titled "Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks". You can find the paper here.

CycleGAN is a model designed for image-to-image translation tasks without the need for paired data. It learns to map images from one domain to another in an unsupervised manner, by simultaneously training two generators and two discriminators. The generators aim to translate images from one domain to another, while the discriminators try to distinguish between translated images and real images from the target domain.

This implementation enables image-to-image translation between two domains using unpaired datasets.
